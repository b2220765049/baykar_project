# Comments are provided throughout this file to help you get started.
# If you need more help, visit the Docker Compose reference guide at
# https://docs.docker.com/go/compose-spec-reference/

# Here the instructions define your application as a service called "app".
# This service is built from the Dockerfile in the current directory.
# You can add other services your application may depend on here, such as a
# database or a cache. For examples, see the Awesome Compose repository:
# https://github.com/docker/awesome-compose
services:
  app:
    build:
      context: .
      dockerfile: DockerFile
      target: final
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_HUB_TOKEN}
      - NO_PROXY=huggingface.co,.huggingface.co,cdn-lfs.huggingface.co,cdn-lfs-us.huggingface.co
    # For local Docker Engine with NVIDIA runtime you can also add this (Compose V2):
    # gpus: all
    volumes:
      - hf-cache:/home/appuser/.cache/huggingface
      - ./data/logs:/app/data/logs
  # Optional UI service that runs the Gradio interface. It builds the same
  # image so the UI code and dependencies are available. The UI will connect
  # to the `app` service using the Docker network at http://app:8000.
  ui:
    build:
      context: .
      dockerfile: DockerFile
      target: final
    command: python UI.py
    ports:
      - "7860:7860"
    environment:
      - API_URL=http://app:8000/query
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=7860
      - HF_TOKEN=${HF_TOKEN}
      - HUGGINGFACE_HUB_TOKEN=${HUGGINGFACE_HUB_TOKEN}
      - NO_PROXY=huggingface.co,.huggingface.co,cdn-lfs.huggingface.co,cdn-lfs-us.huggingface.co
    depends_on:
      - app
    volumes:
      - hf-cache:/home/appuser/.cache/huggingface
      - ./data/logs:/app/data/logs
volumes:
  hf-cache:
